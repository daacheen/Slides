大家好，今天我的报告的论文题目是这个：Azure Data Lake Store: A Hyperscale Distributed File Service for Big Data Analytics。

从这个论文题目可以看出这个论文其实是对这个Azure Data Lake Store系统的一个介绍这个系统是微软的云服务的一个产品，是已经商业化的、大家都可以使用的系统，所以这篇文章的内容主要是系统的基本原理的介绍，也没有涉及太多内部细节。

本次报告将从以下几个部分来介绍：概述、架构、组件、安全性措施、总结和思考。

首先是系统概述

在介绍系统之前需要首先介绍一些它前身或者相关技术。在这个领域中主要有两种平台，数据分析平台和数据存储平台。数据存储平台负责存储大量的数据，可以简单理解成一个大号网盘；数据分析平台负责运行对于这些数据的计算、分析任务。现有的技术主要有这么几个。Cosmos是ADLS之前微软自己内部的一个大数据设施，包括了数据存储平台和基于U-SQL的数据分析平台。ADLA是微软后面对外开放的一个数据分析平台。Hadoop是开源生态下的大数据的存储和分析平台的标杆，同样是包括了存储和分析两个部分。这是Azure Data Lake Analysis的截图，可以看到计算任务的信息，比如运行了多久、每个阶段用时和数量等。

而我们今天要讲的ADLS，是一个数据存储平台，就是它只负责存储大量的数据，其计算任务由专门的任务分析平台负责，比如ADLA。ADLS全程是Azure Data Lake Store，是一个分布式的文件服务/数据存储平台，它是从我们之前讲的Cosmos演化而来，最重要的改进是在微软自己的技术栈之外，支持了开源世界的Hadoop的生态（如HDFS的协议），以吸引更多的使用者。

论文中介绍了ADLS的三个特点，整篇论文也主要是从这三个特点入手来介绍整个系统的。

第一是多层次存储。当前数据越来越多，要求数据能够被低代价地存储，但是在计算任务需要的时候也需要保证一定的读写速度。ADLS中存储分为了两个部分：本地存储和远端存储。当前计算任务需要的数据放在本地存储上、即计算任务所在的机器或者机房上；不需要使用的数据放在远端存储上。在每次计算任务开始时，系统就会自动生成数据获取计划：首先找到计算需要的数据所存放的地方，然后尽可能把计算任务安排到离数据最近的节点上；如果数据只存在于远端存储上，则按需获取数据。通过这种方式可以在数据的存储和使用之间找到一个平衡。

第二个特点是规模巨大，文中所使用的词语是exabyte，查了下一个EB等于一百万TB，可以粗略感受一下数据的规模。由于ADLS是Cosmos系统的演进，所以需要兼容当前的Cosmos系统。文中列出了一些数据，比如比最大的hadoop集群还要多出10倍的节点数，单个文件的大小、每天处理的数据、节点的并行能力，以及迁移数据时还要保证服务不挂。

第三个特点是要求完整的安全和数据共享的措施。毕竟是企业级的产品，对安全性的要求还是比较高的。比如数据可以按照用户、目录和文件的粒度设置权限，使用AAD进行鉴权，数据存储都是加密的且这个密钥可以由用户自己管理等等。这个部分将会在后面介绍。

下面进入第二个部分：系统架构。

首先需要介绍一下这个系统中的文件结构。这个系统叫文件服务嘛，本质是存储文件的，但是由于系统的复杂性，系统中的“文件”和普通的文件是有完全不一样的结构。在ADLS中，一个文件是由一个extent的序列组成的，每个extent由多个最大4MB的block组成，如图所示。每个文件的最后一个extent被称为尾extent，它可能是封闭的或者非封闭的，只有尾extent是非封闭的文件才能对其追加内容。其他的extent都是封闭的。

在extent之外还有个部分文件的概念。一个部分文件是一个连续的extent序列，不同的部分文件可以放在不同的存储层中。同样的，部分文件也可以封闭。如果追加的时候尾部分文件是封闭的，那么会创建一个新的部分文件来追加内容。部分文件之间可以有重叠，但是全部部分文件加起来，需要覆盖一个文件的所有extent。

文件结构讲完了，接下来介绍ADLS的系统架构。整个系统是一个微服务架构，由多个组件组成。一个ADLS集群中有3种节点：后端、前端和微服务节点。后端节点是负责数据存储和计算的主要的节点，这些节点是系统中最多的，毕竟它主要做工作的；而前端节点主要负责网关、路由和控制的控制；微服务节点就是托管系统的各个微服务的。系统中微服务有很多，每个都起到了很重要的作用。在讲解每个微服务的具体工作之前，我们先看三个微服务，通过一个打开文件的场景简单了解系统的工作流程。

比如，我们要求访问/myfolder/ABC这个文件。可以把系统看作一个文件系统，当访问文件时，首先需要根据路径查找到文件。

首先，我们通过负责映射名字和文件对象的Naming Service（NS）服务查找myfolder目录，然后根据它的children找到myfolder的子文件，查找到ABC的文件ID是120。

之后，我们去负责映射文件ID和部分文件的Partial File Management Service（PFM）中查找这个文件的部分文件以及它们所在的存储。可以看到只有ID为4的部分文件对应的文件ID是120.通过Provider ID获得它所在的存储是AS（Azure Storage）。

接下来，我们需要去Azure Storage的Extent Management Service（EMS）中查找这个部分文件所对应的extent，发现这个部分有两个extent，分别在Account01的blob-u和2和blob-v。

最后，我们直接根据这个地址去Azure Storage访问就可以获得这个文件的数据了。

通过这个例子，我们可以对系统中各个微服务之间的交互有了个简单的认识。接下来，我们对每个微服务的作用进行介绍。

我们先介绍刚才示例出现的两个微服务。刚才我们示例中出现的第一个服务就是这个Naming Service（NS），它负责把文件名和文件ID进行映射。可以把这里的文件ID理解成文件系统的inode号对应起来，系统中的其他服务都通过文件ID进行操作文件，这种对应关系就实现了文件名和ID的解耦，使得可以在不移动内容的情况，重命名和移动文件名。和普通的文件系统一样，文件名是支持分层的，这样也方便文件的组织和管理。NS还实现了POSIX风格的权限控制，就是那个对owner, group, other设置read, write, execute的权限的权限，在NS中每个文件的ACL列就是存储的这个权限信息。

接下来是示例的第二步，Partial File Management Service（PFM），部分文件管理服务，它负责把文件ID和每个部分的ID以及其对应的存储提供者，也就是这个Partial File具体存放在哪个存储进行对应。PFM中除了这些之外，还存储一些额外的文件的元信息，如每个部分文件相对于文件的开始和结束偏移量、创建修改时间、文件大小以及它是否封闭的信息。

EMS服务和存储提供者有关，所以我先介绍存储提供者Storage Provider。一个存储提供者是一个单一命名空间（即一个Storage Provider中一个名字的文件只能有一个）、只能追加文件的对象存储系统，它负责存储部分文件，以及部分文件的具体组成extent和文件的具体内容。一个存储提供者在本身的存储系统之外，需要实现存储提供者接口来接入ADLS系统。这个接口的实现运行在SSS上，负责把ADLS统一的文件格式和操作转换到自己的具体实现的具体操作上。

之前提到过，存储提供者分为本地和远端两种。本地存储提供者运行在并把数据存在每个ADLS的后端节点中，使得在这些节点上执行的计算任务可以快速访问这里面的数据。本地存储速度快，但是空间有限。Cosmos Storage Provider是一种本地存储提供者。而远程存储提供者运行在整个集群之外，在需要数据的时候通过接口获取到数据，这种存储访问速度慢，但是灵活、容量大而且价格低廉。Azure Storage是一个Azure提供的通用的对象存储服务，它可以用作ADLS系统的远程服务提供者。

为了把部分文件和extent以及它们具体的存储信息对应起来，每个存储提供者都有一个自己的Extent Management Service（EMS），extent管理服务，它负责把部分文件和它包括的extent以及每个extent存储地点对应起来。示例中访问数据的最后一部，就是通过部分文件查找到它的extent，然后去具体的存储地点进行访问。

接下来介绍系统中的其他服务。第一个是Secure Store Service(SSS)。SSS是一个ADLS服务的入口，每个节点上都有这种服务，每个请求都由ADLS在各个微服务之间进行编排和协调来完成，还会通过重试、熔断等操作处理请求失败和超时这些意外事件。另外，SSS还负责运行前面提到的存储提供者的接口实现。ADLS还负责统计信息、执行带宽和吞吐量的限制等工作。

之后是一个叫RSL-HK的服务，这个名字很奇怪，文中也没写全程是什么，但是这个服务是系统的一个核心基础设施，简单理解，就是管理内部状态的数据库。RSL-HK负责管理各个服务的持久性状态，使得各个服务可以以满足ACID的事务性的方式操作数据，提供了检查点、记录、恢复等各种数据库常见的功能。论文声称它具有高吞吐量和低延迟的特征，大量微服务，例如刚才介绍的NS、PFM以及之后的一些服务都是以RSL-HK为基础实现，即数据存储在RSL-HK中，使用RSL-HK进行操作和管理。从实现来说，RSL-HK基于Paxos协议，使用了SQL Server的内存数据库引擎Hekaton实现，除此之外论文中也没说得更详细。
ADLS中有一个叫Small Append Service（SAS）的服务，它就负责完成小文件的追加工作，以解决hadoop具有的降低追加大量小文件时延迟和性能问题。系统对提供一个统一的文件追加ID，但是会在操作前检测追加文件的大小，如果文件过小就采用SAS，如果是大文件就采用传统的批处理的方法。SAS的主要方法包括使用快速的存储介质（SSD）、或者把多个小文件合并一个大chunk再进行合并。论文声称SAS使得小文件追加的性能提升显著，在图中追加1KB的文件，可以看到打开SAS后的延迟降低非常显著。

计算过程中可能会生成大量的中间数据，所以系统设计了一个专门的Transient Data Store Service（TDSS）来负责存储ADLA计算任务的中间节点，每个运行计算任务的节点中都存在有本服务。论文中专门提到了为了支持事务结束后的debug，ADLA任务完成后TDSS还会保持一定时间的中间数据，对于成功的任务保存几个小时，而失败任务保存数天。

由于整个系统是个商业系统，需要进行计费、限额等操作，所以Throttling Service限流服务专门用来收集每个账号对带宽和读写次数的数据。每50ms，SSS把各个账号的这些数据发送给TS，TS计算出哪些账号对带宽和读写次数的使用超出了它的限额，并要求SSS在接下来的50ms停用超过限额的账号的请求。

系统对于安全性方面也采取了很多措施，例如使用AAD实现了用户请求的认证和授权，在NS中实现的访问控制。进入ADLS后或者ADLS之间的数据传输都是加密的，甚至前面的TDSS中的中间数据都会在未使用的时候进行加密的。

系统中关于加解密的操作主要通过Secret Management Service（SMS）完成。SMS基于RSL-HK实现，负责管理key-value格式的秘密或者与其他秘密仓库交互管理秘密，以及使用可信软件模块（Trusted Software Module）负责数据的加密、解密、压缩、解压操作。一个TSM可以理解成一个独立的软件模块，可以理解成设定了一个数据的安全边界，在TSM中对数据进行操作可以保证数据不会被泄漏或者修改。

系统的加密操作也是比较复杂的，由多个密钥和操作组成。首先是一个主加密密钥（MEK）。每个ADLS账号拥有一个MEK，存储在账号的Azure Key Vault（另一个秘密仓库）中，用户自己管理自己的MEK，可以自己更换、删除、上传自己的密钥等。SMS对每个账号使用它的MEK生成一个数据加密密钥（DEK），存储在ADLS集群中。系统会对每个数据库都进行加密，每个数据块的加密密钥都是通过账号DEK和块ID生成，在TSM中对块进行加密操作。这看起来加密可能会很影响系统性能，但是论文指出在一个读写比例为6:4的U-SQL请求，在时长超过3000小时的请求中，加密解密过程只增加了0.22%的总执行时间。

最后是对论文的总结和思考。

ADLS是一个基于Cosmos、支持Hadoop生态的大数据存储平台，是第一个公开的在超大规模上指出完整文件系统的PaaS平台，支持多层次加密，通过AAD、加密等方式保证了数据的安全和权限控制。它由很多微服务组成，每个微服务之间通过协作完成了系统的功能。

由于整个系统是商业产品，功能等方面已经很完备了，这个系统规模很大复杂度也很高，所以我可以从如果想要自己实现一个类似的系统提一点自己的很简单的想法

1.	当前工程界微服务架构已经不是一个新鲜事了，ADLS对微服务架构的应用也显示出了这个架构可以带来强大的可扩展性和伸缩性。比如为了解决Hadoop的小文件合并的问题，专门用了一个单独的SAS服务来做这个事情。以及整个系统的集群规模也可以说明微服务可以带来强大的伸缩性。微服务的编排方面也业内也已经很成熟了，微软自己有一套Service Fabric，内部的服务应该是用的玩意，我们的系统可以使用Kubernetes来很简单地完成容器调度的工作
2.	整个系统和Azure的生态系统集成地很紧密，比如使用Azure Active Directory进行组织内的认证和鉴权，使用Azure Key Vault进行密钥的管理，以及ADLS的第二代gen2是基于Azure生态的另一个服务。这其实也可以是我们系统的入手点和亮点。比如我们可以使用任何其他LDAP Provider来做授权操作，允许用户接入其他Secret Store，或者开放接口，使得用户可以自己写接口自行扩展其他存储系统等等，这样就使得用户可以有更大的灵活性，不会被绑在Azure生态上
3.	当然就连MS也不能避开Hadoop，所以我们的系统要想有人使用，也不能避开Hadoop和HDFS。所以我们的系统在实现时也需要保证兼容HDFS协议，甚至可以可以直接利用Hadoop的部分组件，例如HDFS文件系统，这样不仅能保证和现有生态的兼容性，还能节省很多重复造轮子的工作量
